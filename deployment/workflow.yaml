# Copyright 2023 Google LLC

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#     https://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

- init:
    assign:
      - project_id: $${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
      - dqm_cloud_function_url: ${CLOUD-FUNCTION-URL}
      - config_files_bucket: ${CLOUD-BUCKET-WITH-CONFIG-FILES}
      - workflow_execution_id: $${sys.get_env("GOOGLE_CLOUD_WORKFLOW_EXECUTION_ID")}
      - error_log: []

- get_file_names_from_bucket:
    call: googleapis.storage.v1.objects.list
    args:
        bucket: $${config_files_bucket}
    result: bucket_metadata

- verify_if_bucket_has_files:
    try:
      assign:
        - files: $${bucket_metadata.items}
    except:
      as: e
      raise: $${"could not locate config files in bucket:" + config_files_bucket}

- run_config_files_loop:
      for:
          value: file
          in: $${bucket_metadata.items}
          steps:
              - get_bucket_file_names:
                  steps:
                  - assignment:
                      assign:
                          - bucket: $${config_files_bucket}
                          - name: $${file.name}
                  - read_from_gcs:
                      call: http.get
                      args:
                          url: $${"https://storage.googleapis.com/download/storage/v1/b/" + config_files_bucket + "/o/" + name}
                          auth:
                              type: OAuth2
                          query:
                              alt: media
                      result: config_json_content
                  - set_variables_from_config:
                      assign:
                        - source_project_id: $${config_json_content.body.source_table.project_id}
                        - source_dataset_id: $${config_json_content.body.source_table.dataset_id}
                        - source_table_name: $${config_json_content.body.source_table.table_name}
                        - log_project_id: $${config_json_content.body.log_table.project_id}
                        - log_dataset_id: $${config_json_content.body.log_table.dataset_id}
                        - log_table_name: $${config_json_content.body.log_table.table_name}
                  - create_log_table_if_not_exists:
                      call: googleapis.bigquery.v2.jobs.query
                      args:
                          projectId: $${log_project_id}
                          body:
                              useLegacySql: false
                              projectId: $${log_project_id}
                              query: $${"CREATE TABLE IF NOT EXISTS " + log_dataset_id + "." + log_table_name + " (dqm_version_id STRING,workflow_execution_id STRING,run_timestamp_utc STRING,project_id STRING,dataset_id STRING,table_name STRING,full_table_id STRING,log_type STRING,column STRING,error STRING,parser STRING,rule STRING,rule_params JSON,value STRING)"}
              - get_table_names:
                  call: googleapis.bigquery.v2.jobs.query
                  args:
                      projectId: $${source_project_id}
                      body:
                          useLegacySql: false
                          projectId: $${source_project_id}
                          query: $${"SELECT table_name FROM `" + source_dataset_id + ".INFORMATION_SCHEMA.TABLES` WHERE table_name LIKE '" + source_table_name + "' ORDER BY creation_time DESC LIMIT " + config_json_content.body.source_table.n_tables_to_check }
                  result: queryResult
              - table_loop:
                  parallel:
                      for:
                          value: row
                          in: $${queryResult.rows}
                          steps:
                              - set_base_variable:
                                  assign:
                                      - table_name: $${row.f[0].v}
                                      - dataset_id: $${source_dataset_id}
                              - get_table_info:
                                  call: googleapis.bigquery.v2.tables.get
                                  args:
                                    projectId: $${source_project_id}
                                    datasetId: $${source_dataset_id}
                                    tableId: $${table_name}
                                  result: table_info
                              - check_if_view:
                                  switch:
                                    - condition: $${table_info.type == "VIEW"}
                                      next: create_temp_table
                                    - condition: $${table_info.type != "VIEW"}
                                      next: column_loop
                              - create_temp_table:
                                  call: googleapis.bigquery.v2.jobs.query
                                  args:
                                    projectId: $${source_project_id}
                                    body:
                                      useLegacySql: false
                                      projectId: $${source_project_id}
                                      maxResults: 1
                                      query: $${"SELECT * FROM " + source_project_id + "." + source_dataset_id + "." + table_name}
                                  result: queryResponse
                              - getJob:
                                  call: googleapis.bigquery.v2.jobs.get
                                  args:
                                    projectId: $${source_project_id}
                                    jobId: $${queryResponse.jobReference.jobId}
                                  result: job
                              - getDestinationTable:
                                  assign:
                                  - destinationTable: $${job.configuration.query.destinationTable}
                              - update table name:
                                    assign:
                                      - dataset_id: $${destinationTable.datasetId}
                                      - table_name: $${destinationTable.tableId}
                              - column_loop:
                                  parallel:
                                      for:
                                          value: column
                                          in: $${keys(config_json_content.body.columns)}
                                          steps:
                                              - call_cloud_function:
                                                    try:
                                                        steps:
                                                            - construct_request:
                                                                assign:
                                                                    - request_body:
                                                                        workflow_execution_id: $${workflow_execution_id}
                                                                        config_file: $${file.name}
                                                                        source_table:
                                                                            project_id: $${source_project_id}
                                                                            dataset_id: $${dataset_id}
                                                                            table_name: $${table_name}
                                                                        display_source_table:
                                                                            project_id: $${source_project_id}
                                                                            dataset_id: $${source_dataset_id}
                                                                            table_name: $${row.f[0].v}
                                                                        log_table:
                                                                            project_id: $${log_project_id}
                                                                            dataset_id: $${log_dataset_id}
                                                                            table_name: $${log_table_name}
                                                                        column_config:
                                                                            column: $${column}
                                                                            parser: $${config_json_content.body.columns[column].parser}
                                                                            rules: $${config_json_content.body.columns[column].rules}
                                                            - log_request:
                                                                call: sys.log
                                                                args:
                                                                    json:
                                                                        description: "Cloud Function Request"
                                                                        request: $${request_body}
                                                                    severity: INFO
                                                            - post_to_cf:
                                                                call: http.post
                                                                args:
                                                                    url: $${dqm_cloud_function_url + "/process_column"}
                                                                    auth:
                                                                        type: OIDC
                                                                        audience: $${dqm_cloud_function_url}
                                                                    body: $${request_body}
                                                                result: log_result
                                                            - log_response:
                                                                call: sys.log
                                                                args:
                                                                    json:
                                                                        description: "Cloud Function Response"
                                                                        response: $${log_result.body}
                                                                    severity: INFO
                                                    except:
                                                        as: e
                                                        steps:
                                                            - log_failed_requests:
                                                                call: sys.log
                                                                args:
                                                                    json: $${e}
                                                                    severity: WARNING
